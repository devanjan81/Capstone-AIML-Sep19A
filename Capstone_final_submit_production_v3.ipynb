{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Capstone_final_submit_production_v3.ipynb","provenance":[{"file_id":"1H5YiL87BPNZESLEMVMGgVN0z6WQJX9UL","timestamp":1599050668674}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"5oA6m8jqg2AA"},"source":["# Capstone Project - Automatic Ticket Assignment\n","## Validation notebook\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"LIh8wUBShmcD"},"source":["### Import Required Libraries"]},{"cell_type":"markdown","metadata":{"id":"w2bMgrHdAI4j","colab_type":"text"},"source":["##### Installing googletrans. It is not avaialble out of box in GoogleTrans"]},{"cell_type":"code","metadata":{"id":"MCz44WfoWAej","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":762},"executionInfo":{"status":"ok","timestamp":1599275549254,"user_tz":-330,"elapsed":10007,"user":{"displayName":"pramod joshi","photoUrl":"","userId":"17245309107987121990"}},"outputId":"e30a1199-37e8-4eef-8971-e34d46d3eee6"},"source":["pip install googletrans\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting googletrans\n","  Downloading https://files.pythonhosted.org/packages/71/3a/3b19effdd4c03958b90f40fe01c93de6d5280e03843cc5adf6956bfc9512/googletrans-3.0.0.tar.gz\n","Collecting httpx==0.13.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/b4/698b284c6aed4d7c2b4fe3ba5df1fcf6093612423797e76fbb24890dd22f/httpx-0.13.3-py3-none-any.whl (55kB)\n","\u001b[K     |████████████████████████████████| 61kB 2.8MB/s \n","\u001b[?25hRequirement already satisfied: chardet==3.* in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans) (3.0.4)\n","Collecting rfc3986<2,>=1.3\n","  Downloading https://files.pythonhosted.org/packages/78/be/7b8b99fd74ff5684225f50dd0e865393d2265656ef3b4ba9eaaaffe622b8/rfc3986-1.4.0-py2.py3-none-any.whl\n","Collecting httpcore==0.9.*\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/d5/e4ff9318693ac6101a2095e580908b591838c6f33df8d3ee8dd953ba96a8/httpcore-0.9.1-py3-none-any.whl (42kB)\n","\u001b[K     |████████████████████████████████| 51kB 5.2MB/s \n","\u001b[?25hRequirement already satisfied: idna==2.* in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans) (2.10)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans) (2020.6.20)\n","Collecting sniffio\n","  Downloading https://files.pythonhosted.org/packages/b3/82/4bd4b7d9c0d1dc0fbfbc2a1e00138e7f3ab85bc239358fe9b78aa2ab586d/sniffio-1.1.0-py3-none-any.whl\n","Collecting hstspreload\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/6e/a09233eb83cebe00543c94ac921af936937cf448ccdd46aaf6f432d4f2dd/hstspreload-2020.9.2-py3-none-any.whl (950kB)\n","\u001b[K     |████████████████████████████████| 952kB 8.8MB/s \n","\u001b[?25hCollecting h2==3.*\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/de/da019bcc539eeab02f6d45836f23858ac467f584bfec7a526ef200242afe/h2-3.2.0-py2.py3-none-any.whl (65kB)\n","\u001b[K     |████████████████████████████████| 71kB 6.9MB/s \n","\u001b[?25hCollecting h11<0.10,>=0.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/fd/3dad730b0f95e78aeeb742f96fa7bbecbdd56a58e405d3da440d5bfb90c6/h11-0.9.0-py2.py3-none-any.whl (53kB)\n","\u001b[K     |████████████████████████████████| 61kB 5.0MB/s \n","\u001b[?25hCollecting contextvars>=2.1; python_version < \"3.7\"\n","  Downloading https://files.pythonhosted.org/packages/83/96/55b82d9f13763be9d672622e1b8106c85acb83edd7cc2fa5bc67cd9877e9/contextvars-2.4.tar.gz\n","Collecting hyperframe<6,>=5.2.0\n","  Downloading https://files.pythonhosted.org/packages/19/0c/bf88182bcb5dce3094e2f3e4fe20db28a9928cb7bd5b08024030e4b140db/hyperframe-5.2.0-py2.py3-none-any.whl\n","Collecting hpack<4,>=3.0\n","  Downloading https://files.pythonhosted.org/packages/8a/cc/e53517f4a1e13f74776ca93271caef378dadec14d71c61c949d759d3db69/hpack-3.0.0-py2.py3-none-any.whl\n","Collecting immutables>=0.9\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/e0/ea6fd4697120327d26773b5a84853f897a68e33d3f9376b00a8ff96e4f63/immutables-0.14-cp36-cp36m-manylinux1_x86_64.whl (98kB)\n","\u001b[K     |████████████████████████████████| 102kB 9.0MB/s \n","\u001b[?25hBuilding wheels for collected packages: googletrans, contextvars\n","  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for googletrans: filename=googletrans-3.0.0-cp36-none-any.whl size=15736 sha256=3aa1210e32828c71c196f1753f93be9ca6a720fd3f02be74b0410da1a31fadd0\n","  Stored in directory: /root/.cache/pip/wheels/28/1a/a7/eaf4d7a3417a0c65796c547cff4deb6d79c7d14c2abd29273e\n","  Building wheel for contextvars (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for contextvars: filename=contextvars-2.4-cp36-none-any.whl size=7666 sha256=f2aa181d2428ff41e07a4dfcd0e1b78e89bf6834413be55ae40282ed31db41f6\n","  Stored in directory: /root/.cache/pip/wheels/a5/7d/68/1ebae2668bda2228686e3c1cf16f2c2384cea6e9334ad5f6de\n","Successfully built googletrans contextvars\n","Installing collected packages: rfc3986, immutables, contextvars, sniffio, hyperframe, hpack, h2, h11, httpcore, hstspreload, httpx, googletrans\n","Successfully installed contextvars-2.4 googletrans-3.0.0 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2020.9.2 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 immutables-0.14 rfc3986-1.4.0 sniffio-1.1.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"I-e38Y9BAU38","colab_type":"text"},"source":["##### Importing NTLK package and downloading the Wordnet corpus"]},{"cell_type":"code","metadata":{"id":"zQv4MqigFXFu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":69},"executionInfo":{"status":"ok","timestamp":1599275551811,"user_tz":-330,"elapsed":12553,"user":{"displayName":"pramod joshi","photoUrl":"","userId":"17245309107987121990"}},"outputId":"661db2d1-42db-44ed-ace8-cc6c055f7d54"},"source":["import nltk\n","nltk.download('wordnet')\n","  "],"execution_count":2,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"DYT29ZPMAg4i","colab_type":"text"},"source":["##### Importing rest of the libarries needed to use this notebook"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"8FRkvqr5hTx0","colab":{},"executionInfo":{"status":"ok","timestamp":1599275553796,"user_tz":-330,"elapsed":14532,"user":{"displayName":"pramod joshi","photoUrl":"","userId":"17245309107987121990"}}},"source":["import warnings\n","warnings.filterwarnings('ignore')\n","\n","import numpy as np\n","import pandas as pd\n","from sklearn import preprocessing\n","import matplotlib.pyplot as plt\n","\n","import nltk;\n","from nltk.stem import WordNetLemmatizer\n","from nltk.corpus import wordnet as wn\n","from nltk.corpus import stopwords\n","import string\n","from googletrans import Translator\n","pd.set_option('display.width', -1)\n","\n","random_seed=22\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n","from tensorflow.keras import optimizers, backend\n","from tensorflow.keras import models\n","\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","from nltk.corpus import wordnet   \n","\n","from nltk.stem import WordNetLemmatizer\n","from nltk.corpus import wordnet as wn\n","wn = nltk.WordNetLemmatizer()\n","import string\n","import re\n","import pickle\n","import os\n","\n","from textblob import TextBlob \n"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cAnXEBllAlxF","colab_type":"text"},"source":["##### mapping google drive"]},{"cell_type":"code","metadata":{"id":"d3zf-Z151Eua","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":124},"executionInfo":{"status":"ok","timestamp":1599275572516,"user_tz":-330,"elapsed":33247,"user":{"displayName":"pramod joshi","photoUrl":"","userId":"17245309107987121990"}},"outputId":"33a17d44-e59e-4cc5-aa66-469e41daf071"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"D86QDB73AlHt","colab_type":"text"},"source":["##### Setting the path for the resources"]},{"cell_type":"code","metadata":{"id":"9d6PqWnIWAep","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1599275572517,"user_tz":-330,"elapsed":33242,"user":{"displayName":"pramod joshi","photoUrl":"","userId":"17245309107987121990"}},"outputId":"df465d7b-537a-40aa-e1d5-98974566b863"},"source":["project_path=os.getcwd()\n","project_path='/content/drive/My Drive/Projects/'\n","print(project_path)\n","#project_path=\"F:\\\\StudyProject\\\\Projects\\\\Final_Team_project\\\\\"\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Projects/\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Q5rnZVSjBC7G","colab_type":"text"},"source":["### Defining various functions needed to predict using the Deep Learning Model"]},{"cell_type":"code","metadata":{"id":"7053D-rh6NWQ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599275572517,"user_tz":-330,"elapsed":33236,"user":{"displayName":"pramod joshi","photoUrl":"","userId":"17245309107987121990"}}},"source":["### Getting the saved model with architecture and weights\n","def get_model():\n","  loaded_model=models.load_model(project_path)\n","  return loaded_model\n","\n","### loading the Tokenizer used for training the model\n","### used to create tokens from the string/text passed into the model\n","def load_tokenizer():\n","  # loading tokenizer\n","  with open(project_path+'/resources/tokenizer.pickle', 'rb') as handle:\n","    tokenizer = pickle.load(handle)\n","  return tokenizer\n","\n","### Routine to translate the input\n","def translate(text):\n","  translator = Translator()\n","  val = translator.translate(text)\n","  return val\n","\n","### Routine to apply the Regex to the inputs\n","def applyRegEx(dd):\n","    symbol = \"\"\"!#$%^`&*();:\\t\\\\\\\"!\\{\\}\\[\\]<>-\\?\\-\\\\\\\"—\\.,1234567890\"\"\"\n","    ### regex function to clean up symbols and some patterns like emails, disclaimer, numbers, hostnames, urls, etc\n","    dout=re.sub(' +', ' ' ,\n","                          re.sub('[^a-zA-z0-9\\s]',' ',\n","                          re.sub(\"\\_ \",' ',\n","                          re.sub(\"\\\\\\\\\",' ',\n","                          re.sub('\\\\[a-zA-Z0-9]+',' ',\n","                          re.sub('(\\__)+',' ',\n","                          re.sub('[{}]'.format(symbol),' ',  \n","                          re.sub('ü','u',\n","                          re.sub('ã','a',\n","                          re.sub('€','e',\n","                          re.sub('Â','a',\n","                          re.sub(\"\\'ll\", ' will',\n","                          re.sub(\"\\'ve\", ' have',\n","                          re.sub(\"\\'s\", ' is',\n","                          re.sub(\"doesn\\'t\",' does not', \n","                          re.sub(\"cant\\'t'\",' cannot',       \n","                          re.sub(\"cant\", ' cannot',\n","                          re.sub('[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+',' ',\n","                          re.sub('[a-zA-Z0-9_.+-]+[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+',' ', \n","                          re.sub('/[a-zA-Z0-9_.+-]+',' ',\n","                          re.sub('\\_[0-9]+',' ',       \n","                          re.sub(\"\\(yes\\/no\\/na\\)\",' ',\n","                          re.sub(\"received from:\",' ',\n","                          re.sub('\\_\\_([a-zA-Z0-9])\\_\\_',' ',\n","                          re.sub('diese mitteilung ist einzig und allein für die nutzung durch den adressaten bestimmt und kann informationen enthalten, die schutzwürdig, vertraulich oder nach geltendem recht von der offenlegung ausgenommen sind. die verbreitung, verteilung oder vervielfältigung dieser mitteilung durch personen, bei denen es sich nicht um die beabsichtigten empfänger handelt, ist streng verboten. wenn diese mitteilung aufgrund eines versehens bei ihnen eingegangen ist, dann benachrichtigen sie bitte den absender und löschen sie diese mitteilung.',' ',\n","                          re.sub('本通信は記載された人物のみを対象として使用されるものとし、特権的かつ機密情報を含み、適用される法律に基づいた情報開示から除外されるものとします。正当な受取人以外のいかなる第三者による本通信の配布、流通、再販は固く禁じられています。また本通信が誤って送信された場合は、送信者に連絡の上、本通信を削除してください。',' ',\n","                          re.sub('this communication is intended solely for the use of the addressee and may contain information that is worthy of protection, confidential or excluded from disclosure under applicable law. the distribution, distribution or reproduction of this communication by persons other than the intended recipients is strictly prohibited. if you have received this message by mistake, please notify the sender and delete this message.',' ',\n","                          re.sub('neste mensaje está destinado al uso exclusivo de la persona a quien está dirigido y puede contener información privilegiada, confidencial y que está exenta de ser revelada conforme con lo dispuesto en la legislación vigente. toda difusión, distribución o reproducción de este mensaje por parte de otra persona que no sea el receptor al que está destinado queda estrictamente prohibida. si recibe este mensaje por error, se ruega que lo notifique al remitente y borre este mensaje.',' ',\n","                          re.sub('select the following link to view the disclaimer in an alternate language.',' ',       \n","                          re.sub('company\\/posts',' ',       \n","                          re.sub('[}/:\\r\\n]',' ',dd)))))))))))))))))))))))))))))))\n","    dout=dout.lower()\n","    return dout\n","\n","\n","#### Routine to load the custom_stopwords used to clean the data\n","def load_stopwords():\n","  pickle_off = open (project_path+\"resources/custom_stopwords.txt\", \"rb\")\n","  custom_stopwords = pickle.load(pickle_off)\n","  return custom_stopwords\n","\n","def load_callerlist():\n","  pickle_off = open (project_path+\"resources/callerlist.txt\", \"rb\")\n","  callerlist = pickle.load(pickle_off)\n","  return callerlist\n","  \n","#### main pipeline to pre-process the input\n","def cleantext(intext,debug):    \n","  if debug=='Y':\n","    print('original ',intext)\n","  text=applyRegEx(intext)\n","  if debug=='Y':\n","    print('regex ',intext)\n","  text = [word for word in re.split(' ',text) if word not in callerlist]\n","  if debug=='Y':\n","    print('caller ',text)\n","  #text =' '.join(text)\n","  #text = [replacementset[word] if word in replacementset else word for word in text.split(\" \")]\n","  if debug=='Y':\n","    print('replacement ',text)\n","  if debug=='Y':\n","    print('delete ',text)\n","  text =' '.join(text)\n","  text = [word for word in text.split(\" \") if word not in custom_stopwords]\n","  if debug=='Y':\n","    print('stop ',text)\n","  text = [word for word in text if not word=='']\n","  if debug=='Y':\n","    print('empty ',text)\n","  text = [wn.lemmatize(word) for word in text]\n","  if debug=='Y':\n","    print('lemat ',text)\n","  text = \" \".join([word for word in text if not len(word)<3])\n","  if debug=='Y':\n","    print('small ',text)\n","  return text\n","\n","### Converting to sequences to input to the model\n","MAXLEN=300\n","def get_seq(in_text):\n","  sequences = tokenizer.texts_to_sequences([in_text])\n","  ptext = pad_sequences(sequences, maxlen=MAXLEN,padding='post')\n","  return ptext"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OLBvhHcWDUSa","colab_type":"text"},"source":["### Loading various objects needed for the model"]},{"cell_type":"code","metadata":{"id":"Z239wZ7NflNf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":433},"executionInfo":{"status":"ok","timestamp":1599275579665,"user_tz":-330,"elapsed":40379,"user":{"displayName":"pramod joshi","photoUrl":"","userId":"17245309107987121990"}},"outputId":"8c27b5a9-8583-4feb-ff45-5554e0e714d6"},"source":["custom_stopwords=load_stopwords()\n","callerlist=load_callerlist()\n","tokenizer=load_tokenizer()\n","loaded_model=models.load_model(project_path)\n","loaded_model.summary()\n"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, 300, 300)          3000300   \n","_________________________________________________________________\n","dropout (Dropout)            (None, 300, 300)          0         \n","_________________________________________________________________\n","conv1d (Conv1D)              (None, 300, 64)           96064     \n","_________________________________________________________________\n","max_pooling1d (MaxPooling1D) (None, 75, 64)            0         \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 75, 300)           438000    \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 75, 300)           0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 22500)             0         \n","_________________________________________________________________\n","dense (Dense)                (None, 22)                495022    \n","=================================================================\n","Total params: 4,029,386\n","Trainable params: 4,029,386\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5Onhb9cn94KD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":190},"executionInfo":{"status":"ok","timestamp":1599275581586,"user_tz":-330,"elapsed":42295,"user":{"displayName":"pramod joshi","photoUrl":"","userId":"17245309107987121990"}},"outputId":"27a4adec-c4cf-4e47-a2b2-548a4e390d90"},"source":["txt=\"hr_tool not opening\"\n","cleantext(txt,'Y')"],"execution_count":8,"outputs":[{"output_type":"stream","text":["original  hr_tool not opening\n","regex  hr_tool not opening\n","caller  ['hr_tool', 'not', 'opening']\n","replacement  ['hr_tool', 'not', 'opening']\n","delete  ['hr_tool', 'not', 'opening']\n","stop  ['hr_tool', 'opening']\n","empty  ['hr_tool', 'opening']\n","lemat  ['hr_tool', 'opening']\n","small  hr_tool opening\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'hr_tool opening'"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"XfjwJb-vDdQY","colab_type":"text"},"source":["### Evaluate the Model using the \"evaluate_text\""]},{"cell_type":"code","metadata":{"id":"OHob8NJfoHpm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":416},"executionInfo":{"status":"ok","timestamp":1599275582512,"user_tz":-330,"elapsed":43213,"user":{"displayName":"pramod joshi","photoUrl":"","userId":"17245309107987121990"}},"outputId":"808784a3-4c67-4964-bb8a-98639ea14658"},"source":["y_pred=[]\n","evaluate_text =\"monitoring tool hostname\"\n","print(\"Input data : \",evaluate_text)\n","ctext=cleantext(evaluate_text,'N')\n","print(ctext)\n","print(get_seq(ctext))\n","print(len(ctext))\n","y_pred=loaded_model.predict(get_seq(ctext))\n","print('--------------------------')\n","print(\"Predicted Class : \", np.argmax(y_pred, axis=1)[0])\n","print('--------------------------')"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Input data :  monitoring tool hostname\n","monitoring tool hostname\n","[[182   2  11   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","    0   0   0   0   0   0   0   0   0   0   0   0]]\n","24\n","--------------------------\n","Predicted Class :  11\n","--------------------------\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BtkkMrl6rz3t","colab_type":"text"},"source":["END of file"]}]}